1
00:00:03 --> 00:00:09
A seven day weather forecast says 
it's going to be 92 degrees Fahrenheit. 

2
00:00:09 --> 00:00:15
What is the 95% confidence interval
around this point estimate?

3
00:00:15 --> 00:00:19
A confidence interval is a range
that contains the actual value 

4
00:00:19 --> 00:00:21
with a given probability. 

5
00:00:22 --> 00:00:25
Is it 92 plus-minus 5?

6
00:00:25 --> 00:00:28
Maybe 92 plus-minus 20?

7
00:00:28 --> 00:00:33
To answer this question, let's see how close
previous forecasts were to reality.

8
00:00:33 --> 00:00:38
Here are historical seven day forecasts 
for New York City 

9
00:00:38 --> 00:00:43
between January, 2022 and September, 2023, 

10
00:00:43 --> 00:00:47
{\an8}and the actual temperature observed 
on day seven.

11
00:00:47 --> 00:00:51
{\an8}Look at the differences between the actuals 
and the forecast. 

12
00:00:51 --> 00:00:55
{\an8}In statistics those are called residuals, 

13
00:00:55 --> 00:01:01
{\an8}and conformal prediction uses even fancier 
term nonconformity score, but 

14
00:01:01 --> 00:01:06
{\an8}I promised no big words so I'll 
just call them differences.

15
00:01:06 --> 00:01:13
{\an8}Next, sort the differences, and pick 
quantiles that correspond to 

16
00:01:13 --> 00:01:16
{\an8}the width of the confidence 
interval we want. 

17
00:01:16 --> 00:01:21
{\an8}In this example, we'll need to pick second
smallest and second largest. 

18
00:01:21 --> 00:01:25
{\an8}Finally, use them to construct 
confidence intervals.

19
00:01:25 --> 00:01:30
{\an8}Looks like 95% confidence interval 
around seven day forecast is 

20
00:01:30 --> 00:01:34
{\an8}plus-minus 10 degrees Fahrenheit.

21
00:01:34 --> 00:01:38
{\an8}This naÃ¯ve approach works if the model
was not built on the same data 

22
00:01:38 --> 00:01:46
{\an8}that was used for calibration. Otherwise 
confidence intervals can be too narrow.

23
00:01:46 --> 00:01:50
{\an8}An extremely overfit model, 
with zero error in-sample, 

24
00:01:50 --> 00:01:55
{\an8}will have overly optimistic,
zero width confidence intervals.

25
00:01:55 --> 00:02:01
{\an8}If we only have one modeling dataset, we 
can split it into development and calibration, 

26
00:02:01 --> 00:02:07
{\an8}fit the model on development data,
then use calibration data 

27
00:02:07 --> 00:02:10
{\an8}for confidence interval estimation.

28
00:02:10 --> 00:02:14
{\an8}This approach is called split conformal.

29
00:02:14 --> 00:02:18
{\an8}It solves the overfitting issue,
but at the cost of using 

30
00:02:18 --> 00:02:20
{\an8}less data for model development.

31
00:02:20 --> 00:02:26
{\an8}The final trick that allows to use 
almost all data for modeling 

32
00:02:26 --> 00:02:30
{\an8}is to split the data in more chunks,
like in cross validation.

33
00:02:30 --> 00:02:35
For each chunk, build the model 
on the data excluding that chunk,

34
00:02:35 --> 00:02:42
then look at the differences between 
that chunk's actuals and model prediction.

35
00:02:42 --> 00:02:46
Because there is more than one model,
it is no longer enough 

36
00:02:46 --> 00:02:49
to take the quantiles 
of the differences. 

37
00:02:49 --> 00:02:55
Instead, one needs to take quantiles 
of model predictions plus the differences.

38
00:02:55 --> 00:03:00
This final algorithm is called CV+.

39
00:03:00 --> 00:03:05
For big words, see "Predictive 
inference with the Jackknife+"

40
00:03:05 --> 00:03:07
by Rina Foygel Barber et al.
